Perception:
created a snapshot of Fetch camera, facing table w/ 3 cylinders, head tilted 1.0 rad and
torso lift fully up.  file: fetch_snapshot.pcd = three_cylinders.pcd

This was created using: 
`rosrun pcl_utils pcd_snapshot`

Can then publish this image using:
`rosrun pcl_utils display_pcd_file`
and respond to prompt w/ file name.  This will publish the PCD file on topic "pcd" with
reference frame: head_camera_rgb_optical_frame, which is viewable in rviz.

Started work on code borrowed from ARIAC2018: interpret_pcd_file.cpp.
Intent is to box-filter pointcloud, convert to world (or fetch torso-link) coordinates,
then convert points on top of table to a 2-D binary image for segmentation by OpenCV.

For off-line processing, note that:
with torso lifted and head tilted (1 rad),
rosrun tf tf_echo torso_lift_link head_camera_rgb_optical_frame

- Translation: [0.244, 0.020, 0.627]
- Rotation: in Quaternion [0.679, -0.679, 0.198, -0.198]
            in RPY (radian) [-2.575, 0.000, -1.570]
            in RPY (degree) [-147.509, 0.000, -89.958]
(do a static pub to get this in program?)


